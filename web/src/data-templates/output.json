[
  {
    "name": "Cassandra",
    "modelType": "Cassandra",
    "description": {
      "short": "The Cassandra output uses the generic implementation with DataFrames.",
      "long": "The Apache Cassandra database is the right choice when you need scalability and high availability without compromising performance. Linear scalability and proven fault-tolerance on commodity hardware or cloud infrastructure make it the perfect platform for mission-critical data.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x11/Outputs#Outputs-Cassandra"
    },
    "properties": [
      {
        "propertyId": "connectionHost",
        "propertyName": "_CONTACT_POINT_",
        "propertyType": "text",
        "regexp": "((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))|(((?![0-9]+$)(?!.*-$)(?!-)[a-zA-Z0-9-]{2,63}))",
        "default": "localhost",
        "required": true,
        "tooltip": "",
        "qa": "fragment-details-cassandra-connectionHost"
      },
      {
        "propertyId": "connectionPort",
        "propertyName": "_PORT_",
        "propertyType": "text",
        "regexp": "(0|([1-9]\\d{0,3}|[1-5]\\d{4}|[6][0-5][0-5]([0-2]\\d|[3][0-5])))",
        "default": "9042",
        "required": true,
        "tooltip": "Cassandra port",
        "hidden": false,
        "qa": "fragment-details-cassandra-connectionPort"
      },
      {
        "propertyId": "keyspace",
        "propertyName": "_KEYSPACE_",
        "propertyType": "text",
        "regexp": "",
        "default": "sparta",
        "required": true,
        "tooltip": "Keyspace name.",
        "qa": "fragment-details-cassandra-keyspace"
      },
      {
        "propertyId": "cluster",
        "propertyName": "_CLUSTER_",
        "propertyType": "text",
        "regexp": "",
        "default": "sparta",
        "required": true,
        "tooltip": "Cluster name.",
        "qa": "fragment-details-cassandra-cluster"
      },
      {
        "propertyId": "keyspaceClass",
        "propertyName": "_KEYSPACE_CLASS_",
        "propertyType": "select",
        "regexp": "simpleStrategy|networkTopologyStrategy",
        "values": [
          {
            "label": "SimpleStrategy",
            "value": "simpleStrategy"
          },
          {
            "label": "NetworkTopologyStrategy",
            "value": "networkTopologyStrategy"
          }
        ],
        "default": "simpleStrategy",
        "required": true,
        "tooltip": "KeySpace class.",
        "qa": "fragment-details-cassandra-keyspaceClass"
      },
      {
        "propertyId": "replication_factor",
        "propertyName": "_REPLICATION_FACTOR_",
        "propertyType": "text",
        "regexp": "\\d*",
        "default": "1",
        "required": true,
        "tooltip": "Specifies the number of replicas of data on multiple nodes.",
        "qa": "fragment-details-cassandra-replication-factor"
      },
      {
        "propertyId": "compactStorage",
        "propertyName": "_COMPACT_STORAGE_",
        "propertyType": "boolean",
        "regexp": "true|false",
        "default": false,
        "required": false,
        "tooltip": "The compact storage directive is used for backward compatibility of CQL 2 applications and data in the legacy (Thrift) storage engine format. To take advantage of CQL 3 capabilities, do not use this directive in new applications. When you create a table using compound primary keys, for every piece of data stored, he column name needs to be stored along with it. Instead of each non-primary key column being stored such that each column corresponds to one column on disk, an entire row is stored in a single column on disk, hence the name compact storage.",
        "qa": "fragment-details-cassandra-compactStorage"
      },
      {
        "propertyId": "analyzer",
        "propertyName": "_LUCENE_ANALYZER_",
        "propertyType": "text",
        "regexp": "",
        "default": "english",
        "required": false,
        "tooltip": "The analyzer for text index fields, this feature is for the Stratio’s Cassandra Lucene Index",
        "qa": "fragment-details-cassandra-analyzer"
      },
      {
        "propertyId": "refreshSeconds",
        "propertyName": "_REFRESH_SECONDS_",
        "propertyType": "text",
        "regexp": "\\d*",
        "default": "1",
        "required": false,
        "tooltip": "The number of seconds between refresh lucene index operations, this feature is for the Stratio’s Cassandra Lucene Index",
        "qa": "fragment-details-cassandra-refreshSeconds"
      },
      {
        "propertyId": "dateFormat",
        "propertyName": "_DATE_FORMAT_",
        "propertyType": "select",
        "regexp": "",
        "values": [
          {
            "label": "yyyy-mm-dd HH:mm",
            "value": "yyyy-mm-dd HH:mm"
          },
          {
            "label": "yyyy-mm-dd HH:mm:ss",
            "value": "yyyy-mm-dd HH:mm:ss"
          },
          {
            "label": "yyyy-mm-dd HH:mmZ",
            "value": "yyyy-mm-dd HH:mmZ"
          },
          {
            "label": "yyyy-mm-dd HH:mm:ssZ",
            "value": "yyyy-mm-dd HH:mm:ssZ"
          },
          {
            "label": "yyyy-mm-dd'T'HH:mm",
            "value": "yyyy-mm-dd'T'HH:mm"
          },
          {
            "label": "yyyy-mm-dd'T'HH:mmZ",
            "value": "yyyy-mm-dd'T'HH:mmZ"
          },
          {
            "label": "yyyy-mm-dd'T'HH:mm:ss",
            "value": "yyyy-mm-dd'T'HH:mm:ss"
          },
          {
            "label": "yyyy-mm-dd'T'HH:mm:ssZ",
            "value": "yyyy-mm-dd'T'HH:mm:ssZ"
          },
          {
            "label": "yyyy-mm-dd",
            "value": "yyyy-mm-dd"
          },
          {
            "label": "yyyy-mm-ddZ",
            "value": "yyyy-mm-ddZ"
          }
        ],
        "default": "yyyy-mm-dd HH:mm",
        "required": false,
        "tooltip": "The date format for the date fields indexed, this feature is for the Stratio’s Cassandra Lucene Index",
        "qa": "fragment-details-cassandra-dateFormat"
      },
      {
        "propertyId": "sparkProperties",
        "propertyName": "_SPARK_PROPERTIES_",
        "propertyType": "list",
        "default": "",
        "required": false,
        "tooltip": "",
        "qa": "fragment-details-cassandra-spark",
        "fields": [
          {
            "propertyId": "sparkPropertyKey",
            "propertyName": "_SPARK_PROPERTY_KEY_",
            "propertyType": "text",
            "regexp": "",
            "default": "spark.cassandra.connection.keep_alive_ms",
            "hidden": false,
            "required": false,
            "qa": "fragment-details-cassandra-sparkPropertyKey"
          },
          {
            "propertyId": "sparkPropertyValue",
            "propertyName": "_SPARK_PROPERTY_VALUE_",
            "propertyType": "text",
            "regexp": "",
            "default": "180000",
            "hidden": false,
            "required": true,
            "qa": "fragment-details-cassandra-sparkPropertyValue"
          }
        ]
      }
    ]
  },
  {
    "name": "CSV",
    "modelType": "Csv",
    "description": {
      "short": "Persist your data in HDFS with CSV format.",
      "long": "Persist your data in HDFS with CSV format.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x11/Outputs#Outputs-CSV"
    },
    "properties": [
      {
        "propertyId": "path",
        "propertyName": "_PATH_",
        "propertyType": "text",
        "regexp": "^[a-zA-Z0-9:_\\.\\-\\+/\\\\]{2,}\\.csv$",
        "default": "path_to_csv.csv",
        "required": true,
        "qa": "fragment-details-csv-path"
      },
      {
        "propertyId": "header",
        "propertyName": "_HEADER_",
        "propertyType": "boolean",
        "regexp": "true|false",
        "default": false,
        "required": false,
        "qa": "fragment-details-csv-header"
      },
      {
        "propertyId": "inferSchema",
        "propertyName": "_INFER_SCHEMA_",
        "propertyType": "boolean",
        "regexp": "true|false",
        "default": false,
        "required": false,
        "qa": "fragment-details-csv-inferSchema"
      },
      {
        "propertyId": "delimiter",
        "propertyName": "_DELIMITER_",
        "propertyType": "text",
        "tooltip": "Any character is accepted except: \\ \" #",
        "regexp": "[^\"#\\\\]",
        "maxlength": "1",
        "default": ",",
        "trim": false,
        "required": false,
        "qa": "fragment-details-csv-delimiter"
      }
    ]
  },
  {
    "name": "Elasticsearch",
    "modelType": "ElasticSearch",
    "description": {
      "short": "The Elasticsearch output uses the generic implementation with DataFrames.",
      "long": "Elasticsearch is a search server based on Lucene. It provides a distributed, multitenant-capable full-text search engine with a RESTful web interface and schema-free JSON documents.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x11/Outputs#Outputs-Elasticsearch"
    },
    "properties": [
      {
        "propertyId": "nodes",
        "propertyName": "_NODES_",
        "propertyType": "list",
        "default": "",
        "required": true,
        "hidden": false,
        "limit": 0,
        "tooltip": "",
        "qa": "fragment-details-elasticSearch-nodes",
        "fields": [
          {
            "propertyId": "node",
            "propertyName": "_HOST_",
            "propertyType": "text",
            "regexp": "((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))|(((?![0-9]+$)(?!.*-$)(?!-)[a-zA-Z0-9-]{2,63}))",
            "default": "localhost",
            "required": true,
            "qa": "fragment-details-elasticSearch-node"
          },
          {
            "propertyId": "tcpPort",
            "propertyName": "_TCP_PORT_",
            "propertyType": "text",
            "regexp": "(0|([1-9]\\d{0,3}|[1-5]\\d{4}|[6][0-5][0-5]([0-2]\\d|[3][0-5])))",
            "default": "9300",
            "required": true,
            "qa": "fragment-details-elasticSearch-tcpPort"
          },
          {
            "propertyId": "httpPort",
            "propertyName": "_HTTP_PORT_",
            "propertyType": "text",
            "regexp": "(0|([1-9]\\d{0,3}|[1-5]\\d{4}|[6][0-5][0-5]([0-2]\\d|[3][0-5])))",
            "default": "9200",
            "required": true,
            "qa": "fragment-details-elasticSearch-httpPort"
          }
        ]
      },
      {
        "propertyId": "clusterName",
        "propertyName": "_CLUSTERNAME_",
        "propertyType": "text",
        "regexp": "",
        "default": "elasticsearch",
        "required": true,
        "qa": "fragment-details-elasticSearch-clusterName"
      },
      {
        "propertyId": "idField",
        "propertyName": "_ID_FIELD_",
        "propertyType": "text",
        "regexp": "",
        "default": "",
        "required": false,
        "qa": "fragment-details-elasticSearch-idField"
      },
      {
        "propertyId": "indexMapping",
        "propertyName": "_INDEX_MAPPING_",
        "propertyType": "text",
        "regexp": "",
        "default": "sparta",
        "required": false,
        "qa": "fragment-details-elasticSearch-indexMapping"
      }
    ]
  },
  {
    "name": "MongoDb",
    "modelType": "MongoDb",
    "description": {
      "short": "MongoDB is an open-source document database, and the leading NoSQL database.",
      "long": "MongoDB is an open-source document database that provides high performance, high availability, and automatic scaling.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x11/Outputs#Outputs-MongoDB"
    },
    "properties": [
      {
        "propertyId": "hosts",
        "propertyName": "_HOSTS_",
        "propertyType": "list",
        "default": "",
        "required": true,
        "tooltip": "This parameter connection routes specified the nodes of a cluster of MongoDB, with different replica set or with sharding.",
        "qa": "fragment-details-mongoDb-hosts",
        "fields": [
          {
            "propertyId": "host",
            "propertyName": "_HOST_",
            "propertyType": "text",
            "regexp": "((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))|(((?![0-9]+$)(?!.*-$)(?!-)[a-zA-Z0-9-]{2,63}))",
            "default": "localhost",
            "hidden": false,
            "required": true,
            "qa": "fragment-details-mongoDb-hostName"
          },
          {
            "propertyId": "port",
            "propertyName": "_PORT_",
            "propertyType": "text",
            "regexp": "(0|([1-9]\\d{0,3}|[1-5]\\d{4}|[6][0-5][0-5]([0-2]\\d|[3][0-5])))",
            "default": "27017",
            "hidden": false,
            "required": true,
            "qa": "fragment-details-mongoDb-port"
          }
        ]
      },
      {
        "propertyId": "dbName",
        "propertyName": "_DATEBASE_NAME_",
        "propertyType": "text",
        "regexp": "",
        "default": "sparta",
        "required": true,
        "tooltip": "Name of the database.",
        "qa": "fragment-details-mongoDb-dbName"
      },
      {
        "propertyId": "connectionsPerHost",
        "propertyName": "_CONNECTIONS_PER_HOST_",
        "propertyType": "text",
        "regexp": "\\d*",
        "default": "5",
        "required": false,
        "tooltip": "Number of connections per host",
        "qa": "fragment-details-mongoDb-connectionsPerHost"
      },
      {
        "propertyId": "threadsAllowedToBlock",
        "propertyName": "_THREADS_ALLOWED_TO_BLOCK_",
        "propertyType": "text",
        "regexp": "\\d*",
        "default": "10",
        "required": false,
        "tooltip": "This multiplier, multiplied with the connectionsPerHost setting, gives the maximum number of threads that may be waiting for a connection to become available from the pool.",
        "qa": "fragment-details-mongoDb-threadsAllowedToBlock"
      },
      {
        "propertyId": "language",
        "propertyName": "_LANGUAGE_",
        "propertyType": "select",
        "regexp": "",
        "values": [
          {
            "label": "danish",
            "value": "danish"
          },
          {
            "label": "dutch",
            "value": "dutch"
          },
          {
            "label": "english",
            "value": "english"
          },
          {
            "label": "finnish",
            "value": "finnish"
          },
          {
            "label": "french",
            "value": "french"
          },
          {
            "label": "german",
            "value": "german"
          },
          {
            "label": "hungarian",
            "value": "hungarian"
          },
          {
            "label": "italian",
            "value": "italian"
          },
          {
            "label": "norwegian",
            "value": "norwegian"
          },
          {
            "label": "portuguese",
            "value": "portuguese"
          },
          {
            "label": "romanian",
            "value": "romanian"
          },
          {
            "label": "russian",
            "value": "russian"
          },
          {
            "label": "spanish",
            "value": "spanish"
          },
          {
            "label": "swedish",
            "value": "swedish"
          },
          {
            "label": "turkish",
            "value": "turkish"
          }
        ],
        "default": "",
        "required": false,
        "tooltip": "Specify the language of the tokenizer in the full-text index in MongoDB, each document inserted must have this key-value.",
        "qa": "fragment-details-mongoDb-language"
      },
      {
        "propertyId": "retrySleep",
        "propertyName": "_RETRY_SLEEP_",
        "propertyType": "text",
        "regexp": "\\d*",
        "default": "1000",
        "required": false,
        "tooltip": "The number of milliseconds to wait for reconnect with MongoDb nodes when the last client fails. It is recommendable to set less time to the slide interval of the streaming window.",
        "qa": "fragment-details-mongoDb-retrySleep"
      }
    ]
  },
  {
    "name": "Parquet",
    "modelType": "Parquet",
    "description": {
      "short": "Parquet output uses the generic implementation with DataFrames.",
      "long": "Apache Parquet is a columnar storage format available to any project in the Hadoop ecosystem, regardless of the choice of data processing framework, data model or programming language.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/latSPARTA0x11est/Outputs#Outputs-Parquet"
    },
    "properties": [
      {
        "propertyId": "path",
        "propertyName": "_PATH_",
        "propertyType": "text",
        "regexp": "",
        "default": "",
        "required": true,
        "tooltip": "",
        "qa": "fragment-details-parquet-path"
      },
      {
        "propertyId": "partitionBy",
        "propertyName": "_PARTITION_BY_",
        "propertyType": "text",
        "regexp": "",
        "required": false,
        "tooltip": "",
        "qa": "fragment-details-parquet-partitionBy"
      }
    ]
  },
  {
    "name": "Print",
    "modelType": "Print",
    "description": {
      "short": "Print output uses the generic implementation with DataFrames, this implementation print each dataframe with his schema.",
      "long": "Print output uses the generic implementation with DataFrames, this implementation print each dataframe with his schema.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x11/Outputs#Outputs-Print"
    },
    "properties": [
    ]
  },
  {
    "name": "Redis",
    "modelType": "Redis",
    "description": {
      "short": "The output of Redis use the generic implementation with DataFrames.",
      "long": "The output of Redis use the generic implementation with DataFrames. Redis is an open source (BSD licensed), in-memory data structure store, used as database, cache and message broker.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x11/Outputs#Outputs-Redis"
    },
    "properties": [
      {
        "propertyId": "hostname",
        "propertyName": "_HOST_",
        "propertyType": "text",
        "regexp": "((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))|(((?![0-9]+$)(?!.*-$)(?!-)[a-zA-Z0-9-]{2,63}))",
        "default": "localhost",
        "required": true,
        "tooltip": "Hostname of the server",
        "qa": "fragment-details-redis-hostname"
      },
      {
        "propertyId": "port",
        "propertyName": "_PORT_",
        "propertyType": "text",
        "regexp": "(0|([1-9]\\d{0,3}|[1-5]\\d{4}|[6][0-5][0-5]([0-2]\\d|[3][0-5])))",
        "default": "6379",
        "required": true,
        "tooltip": "Port of the server",
        "qa": "fragment-details-redis-port"
      }
    ]
  },
  {
  "name": "Kafka",
  "modelType": "Kafka",
  "description": {
    "short": "Apache Kafka is publish-subscribe messaging rethought as a distributed commit log.",
    "long": "Apache Kafka is publish-subscribe messaging rethought as a distributed commit log. Based on the received-based approach (https://spark.apache.org/docs/latest/streaming-kafka-integration.html)",
    "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x11/Outputs#Outputs-Kafka"
  },
  "properties": [
    {
      "propertyId": "metadata.broker.list",
      "propertyName": "_METADATA_BROKER_LIST_",
      "propertyType": "list",
      "regexp": "",
      "default": "",
      "required": true,
      "tooltip": "Kafka host/port to connect",
      "qa": "fragment-details-kafka-metadata-broker-list",
      "fields": [
        {
          "propertyId": "host",
          "propertyName": "_HOST_",
          "propertyType": "text",
          "regexp": "((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))|(((?![0-9]+$)(?!.*-$)(?!-)[a-zA-Z0-9-]{2,63}))",
          "default": "localhost",
          "required": true,
          "tooltip": "Kafka's address.",
          "hidden": false,
          "qa": "fragment-details-kafka-host"
        },
        {
          "propertyId": "port",
          "propertyName": "_PORT_",
          "propertyType": "text",
          "regexp": "(0|([1-9]\\d{0,3}|[1-5]\\d{4}|[6][0-5][0-5]([0-2]\\d|[3][0-5])))",
          "default": "9092",
          "required": true,
          "tooltip": "Kafka's port.",
          "hidden": false,
          "qa": "fragment-details-kafka-port"
        }
      ]
    },
    {
      "propertyId": "serializer.class",
      "propertyName": "_SERIALIZER_",
      "propertyType": "text",
      "regexp": "",
      "default": "kafka.serializer.StringEncoder",
      "required": true,
      "tooltip": "The serializer class for messages",
      "qa": "fragment-details-kafka-serializer-class"
    },
    {
      "propertyId": "request.required.acks",
      "propertyName": "_REQUIRED_ACKS_",
      "propertyType": "boolean",
      "regexp": "true|false",
      "default": false,
      "required": false,
      "tooltip": "Specify whether producer waits for an acknowledgment from the broker, or not",
      "qa": "fragment-details-kafka-request-required-acks"
    },
    {
      "propertyId": "producer.type",
      "propertyName": "_PRODUCER_TYPE_",
      "propertyType": "text",
      "regexp": "async|sync",
      "default": "async",
      "required": true,
      "tooltip": "This parameter specifies whether the messages are sent asynchronously in a background thread",
      "qa": "fragment-details-kafka-producer-type"
    },
    {
      "propertyId": "batch.num.messages",
      "propertyName": "_BATCH_NUM_MESSAGES_",
      "propertyType": "text",
      "regexp": "[0-9]+",
      "default": "200",
      "required": true,
      "tooltip": "The number of messages to send in one batch when using async mode",
      "qa": "fragment-details-kafka-batch-num-messages"
    },
    {
      "propertyId": "kafkaProperties",
      "propertyName": "_KAFKA_PROPERTIES_",
      "propertyType": "list",
      "default": "",
      "required": false,
      "tooltip": "",
      "qa": "fragment-details-kafka-properties",
      "fields": [
        {
          "propertyId": "kafkaPropertyKey",
          "propertyName": "_KAFKA_PROPERTY_KEY_",
          "propertyType": "text",
          "regexp": "",
          "default": "",
          "hidden": false,
          "required": false,
          "qa": "fragment-details-kafka-kafkaPropertyKey"
        },
        {
          "propertyId": "kafkaPropertyValue",
          "propertyName": "_KAFKA_PROPERTY_VALUE_",
          "propertyType": "text",
          "regexp": "",
          "default": "",
          "hidden": false,
          "required": false,
          "qa": "fragment-details-kafka-kafkaPropertyValue"
        }
      ]
    }
  ]
  },
  {
    "name": "Jdbc",
    "modelType": "Jdbc",
    "description": {
      "short": "With one jdbc connection is possible to write data into SQL Databases.",
      "long": "With one jdbc connection is possible to write data into SQL Databases. Using the generic implementation provided by Spark Datasources Api.",
      "learnMore": "http://spark.apache.org/docs/latest/sql-programming-guide.html#data-sources"
    },
    "properties": [
      {
        "propertyId": "url",
        "propertyName": "_JDBC_URL_",
        "propertyType": "text",
        "regexp": "",
        "default": "jdbc:postgresql:dbserver",
        "required": true,
        "tooltip": "Url to connect to one relational Database with jdbc",
        "qa": "fragment-details-jdbc-url"
      }
    ]
  },
  {
    "name": "Http",
    "modelType": "Http",
    "description": {
      "short": "Enables you to do POST requests to a certain URL",
      "long": "Enables you to do an HTTP POST request to a URL specifying if the data is to be passed through format with aparamter or attached in the request body.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x11/Outputs#Outputs-HTTPPost"
    },
    "properties": [
      {
        "propertyId": "url",
        "propertyName": "_URL_",
        "propertyType": "text",
        "regexp": "",
        "default": "",
        "required": true,
        "tooltip": "",
        "qa": "fragment-details-http-url"
      },
      {
        "propertyId": "connTimeout",
        "propertyName": "_CONN_TIMEOUT_",
        "propertyType": "text",
        "regexp": "",
        "default" : 1000,
        "required": false,
        "tooltip": "Value for the connection timeout. Default to 1000ms.",
        "qa": "fragment-details-http-output-conn-timeout"
      },
      {
        "propertyId": "readTimeout",
        "propertyName": "_READ_TIMEOUT_",
        "propertyType": "text",
        "regexp": "",
        "default" : 5000,
        "required": false,
        "tooltip": "Value for the read timeout. Default to 5000ms.",
        "qa": "fragment-details-http-output-read-timeout"
      },
      {
        "propertyId": "outputFormat",
        "propertyName": "_OUTPUT_FORMAT_",
        "propertyType": "select",
        "regexp": "json|row",
        "values": [
          {
            "label": "Json",
            "value": "json"
          },
          {
            "label": "Row",
            "value": "row"
          }
        ],
        "default": "json",
        "required": true,
        "tooltip": "Sets whether the output should be given as Json or row of String values",
        "qa": "fragment-details-http-output-format"
      },
      {
        "propertyId": "delimiter",
        "propertyName": "_DELIMITER_",
        "propertyType": "text",
        "tooltip": "Only eligible if output format is set to Row. Any character is accepted except: \\ \" #",
        "regexp": "[^\"#\\\\]",
        "maxLength": "1",
        "default": ",",
        "trim": false,
        "required": false,
        "qa": "fragment-details-http-delimiter"
      },
      {
        "propertyId": "postType",
        "propertyName": "_POST_TYPE_",
        "propertyType": "select",
        "regexp": "body|parameter",
        "values": [
          {
            "label": "Body",
            "value": "body"
          },
          {
            "label": "Parameter",
            "value": "parameter"
          }
        ],
        "default": "body",
        "required": true,
        "tooltip": "Sets whether the data should be send in the body or as a named parameter in a form",
        "qa": "fragment-details-http-post-type"
      },
      {
        "propertyId": "parameterName",
        "propertyName": "_PARAMETER_NAME_",
        "propertyType": "text",
        "regexp": "",
        "default" : "",
        "required": false,
        "tooltip": "Eligible only if post type is set to parameter. Names the data sent",
        "qa": "fragment-details-http-parameter-name"
      }
    ]
  },
  {
    "name": "FileSystem",
    "modelType": "FileSystem",
    "description": {
      "short": "Saves the processed data to file into any storage service",
      "long": "This output enables you to save the processed data into to a file into any storage service such as HDFS, Amazon S3, Azure or locally.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x11/Outputs#Outputs-Filesystem"
    },
    "properties": [
      {
        "propertyId": "path",
        "propertyName": "_PATH_",
        "propertyType": "text",
        "regexp": "",
        "default": "",
        "required": true,
        "tooltip": "",
        "qa": "fragment-details-filesystem-path"
      },
      {
        "propertyId": "outputFormat",
        "propertyName": "_OUTPUT_FORMAT_",
        "propertyType": "select",
        "regexp": "json|row",
        "values": [
          {
            "label": "Json",
            "value": "json"
          },
          {
            "label": "Row",
            "value": "row"
          }
        ],
        "default": "json",
        "required": true,
        "tooltip": "Sets whether the output should be written as Json or plain text with just the row values.",
        "qa": "fragment-details-filesystem-format"
      },
      {
        "propertyId": "delimiter",
        "propertyName": "_DELIMITER_",
        "propertyType": "text",
        "tooltip": "Only eligible if output format is set to Row. Any character is accepted except: \\ \" #",
        "regexp": "[^\"#\\\\]",
        "maxLength": "1",
        "default": ",",
        "trim": false,
        "required": false,
        "qa": "fragment-details-filesystem-delimiter"
      },
      {
        "propertyId": "fileWithDate",
        "propertyName": "_FILE_WITH_DATE_",
        "propertyType": "select",
        "values": [
          {
            "label": "Yes",
            "value": "true"
          },
          {
            "label": "No",
            "value": "false"
          }
        ],
        "default": "true",
        "required": true,
        "tooltip": "Add the current date to the file name.",
        "qa": "fragment-details-filesystem-file-with-date"
      },
      {
        "propertyId": "dateFormat",
        "propertyName": "_DATE_FORMAT_",
        "propertyType": "select",
        "regexp": "",
        "values": [
          {
            "label": "yyyy-mm-dd'-'HH.mm",
            "value": "YYYY-MM-DD'-'HH.mm"
          },
          {
            "label": "yyyy-mm-dd'-'HH.mm.ss",
            "value": "YYYY-MM-DD'-'HH.mm.ss"
          },
          {
            "label": "yyyy-mm-dd'-'HH.mmZ",
            "value": "YYYY-MM-DD'-'HH.mmZ"
          },
          {
            "label": "yyyy-mm-dd'-'HH.mm.ssZ",
            "value": "YYYY-MM-DD'-'HH.mm.ssZ"
          },
          {
            "label": "yyyy-mm-dd'T'HH.mm",
            "value": "YYYY-MM-DD'T'HH.mm"
          },
          {
            "label": "yyyy-mm-dd'T'HH.mmZ",
            "value": "YYYY-MM-DD'T'HH.mmZ"
          },
          {
            "label": "yyyy-mm-dd'T'HH.mm.ss",
            "value": "YYYY-MM-DD'T'HH.mm.ss"
          },
          {
            "label": "yyyy-mm-dd'T'HH.mm.ssZ",
            "value": "YYYY-MM-DD'T'HH.mm.ssZ"
          },
          {
            "label": "yyyy-mm-dd",
            "value": "YYYY-MM-DD"
          },
          {
            "label": "yyyy-mm-ddZ",
            "value": "YYYY-MM-DDZ"
          }
        ],
        "default": "YYYY-MM-DD'-'HH.mm.ss",
        "required": false,
        "tooltip": "The date format to be appended to the file name. Only used if Append date is set to yes.",
        "qa": "fragment-details-filesystem-date-format"
      },
      {
        "propertyId": "partitionUntil",
        "propertyName": "_PARTITION_UNTIL_",
        "propertyType": "select",
        "regexp": "",
        "values": [
          {
            "label": "Year",
            "value": "YYYY"
          },
          {
            "label": "Month",
            "value": "MM"
          },
          {
            "label": "Day",
            "value": "DD"
          },
          {
            "label": "Hour",
            "value": "HH"
          },
          {
            "label": "Minutes",
            "value": "mm"
          },
          {
            "label": "Seconds",
            "value": "ss"
          },
          {
            "label": "No partition",
            "value": "NONE"
          }
        ],
        "default": "NONE",
        "required": false,
        "tooltip": "Sets the limit the date will be partitioned, creating sub-folders inside the specified the given path",
        "qa": "fragment-details-filesystem--partition-until"
      }
    ]
  }
]
